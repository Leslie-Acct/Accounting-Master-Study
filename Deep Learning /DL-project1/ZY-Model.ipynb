{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5484000f",
   "metadata": {},
   "source": [
    "You are provided with a tabular dataset containing 19 predictor features and 1 continuous target variable. Your task is to build a neural network in keras/tensorflow to predict the target variable. The data is separated into a train set of 1875 data samples, and a test set of 625 data samples.\n",
    "\n",
    "The jupyter notebook should contain the following elements:\n",
    "\n",
    "- Preprocessing of your datasets according to the requirements of neural networks. (different features have different descriptive statistics!)\n",
    "- Implementation of 3 benchmark models: a linear model, a tree-based model and a neural network that has not been tuned. \n",
    "- Tuning of a neural network using a hyperparameter optimization library of your choice. The code for hyperparameter tuning should include regularization. \n",
    "- A well annotated plot showing the train vs. validation loss of the best performing neural network. Based on the plot you should interpret the model fit with max. 2 sentences. Anything beyond these 2 sentences will not participate in the evaluation!\n",
    "- Additionally, you should provide an interpretation of why you believe the best performing architecture is suitable for your task in max. 3 sentences.\n",
    "- A table showing all results (on a validation subset) from the tuned network and your benchmarks.\n",
    "- Well documented code, which is divided into functions, classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecca60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f57a2",
   "metadata": {},
   "source": [
    "First：Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd660576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predictor features on the train set:\n",
    "train_X=pd.read_csv('train_X.csv',sep=',',header=0,index_col=0)\n",
    "#Target variable on the train set:\n",
    "train_y=pd.read_csv('train_y.csv',sep=',',header=0,index_col=0)\n",
    "#Predictor features on the test set:\n",
    "test_X=pd.read_csv('test_X.csv',sep=',',header=0,index_col=0)\n",
    "#Demo predictions file:\n",
    "demo_predictions=pd.read_csv('Demo_Predictions.csv',sep=',',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921078c",
   "metadata": {},
   "source": [
    "Second:Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fbb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the original training set \n",
    "# into sub-training set (80%)for training the model parameters) \n",
    "# and validation set (20%) for tuning hyperparameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_subtrain_train, x_val_train, y_subtrain_train, y_val_train = train_test_split(\n",
    "    train_X, train_y, test_size=0.2, shuffle=True, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d1695",
   "metadata": {},
   "source": [
    "Third："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6627ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale x and y\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_scalar = StandardScaler()\n",
    "x_subtrain_train_scaled=x_scalar.fit_transform(x_subtrain_train)\n",
    "x_val_train_scaled =x_scalar.transform(x_val_train)\n",
    "x_test_scaled=x_scalar.transform(test_X)\n",
    "\n",
    "y_scalar = StandardScaler()\n",
    "y_subtrain_train_scaled=y_scalar.fit_transform(y_subtrain_train.values.reshape(-1, 1))\n",
    "y_val_train_scaled=y_scalar.transform(y_val_train.values.reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb14f4",
   "metadata": {},
   "source": [
    "The first benchmark: Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8279bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7  \\\n",
      "1   1.000000  0.655096 -0.524821  0.973878  0.464945  0.010382 -0.378565   \n",
      "2   0.655096  1.000000 -0.853540  0.623291  0.827375 -0.027750 -0.361367   \n",
      "3  -0.524821 -0.853540  1.000000 -0.483147 -0.597238 -0.009859  0.324112   \n",
      "4   0.973878  0.623291 -0.483147  1.000000  0.366328 -0.015168 -0.396542   \n",
      "5   0.464945  0.827375 -0.597238  0.366328  1.000000 -0.024547 -0.159408   \n",
      "6   0.010382 -0.027750 -0.009859 -0.015168 -0.024547  1.000000  0.000112   \n",
      "7  -0.378565 -0.361367  0.324112 -0.396542 -0.159408  0.000112  1.000000   \n",
      "8  -0.823443 -0.634933  0.480116 -0.882598 -0.361349 -0.005224  0.506974   \n",
      "9  -0.036005 -0.041030 -0.003644 -0.031394 -0.057901 -0.038841  0.007337   \n",
      "10 -0.494435 -0.452051  0.207982 -0.544791 -0.320963  0.033682  0.212477   \n",
      "11 -0.012211  0.030721 -0.007077 -0.007133  0.018431  0.012251 -0.025603   \n",
      "12 -0.126812 -0.682921  0.651756 -0.006929 -0.840684  0.016807  0.011020   \n",
      "13  0.938543  0.614312 -0.484633  0.962189  0.355447 -0.022866 -0.422552   \n",
      "14  0.904159  0.668949 -0.429556  0.953044  0.409505 -0.018878 -0.401222   \n",
      "15 -0.811096 -0.664780  0.370847 -0.870573 -0.419355  0.021834  0.380596   \n",
      "16 -0.905077 -0.652106  0.414147 -0.941772 -0.411024  0.022447  0.379514   \n",
      "17 -0.867263 -0.604213  0.380186 -0.888705 -0.394640  0.024154  0.337786   \n",
      "18  0.123172  0.650301 -0.630842  0.009017  0.789274 -0.012498 -0.013186   \n",
      "19  0.804535  0.557634 -0.353200  0.824460  0.364130 -0.028275 -0.313775   \n",
      "\n",
      "           8         9        10        11        12        13        14  \\\n",
      "1  -0.823443 -0.036005 -0.494435 -0.012211 -0.126812  0.938543  0.904159   \n",
      "2  -0.634933 -0.041030 -0.452051  0.030721 -0.682921  0.614312  0.668949   \n",
      "3   0.480116 -0.003644  0.207982 -0.007077  0.651756 -0.484633 -0.429556   \n",
      "4  -0.882598 -0.031394 -0.544791 -0.007133 -0.006929  0.962189  0.953044   \n",
      "5  -0.361349 -0.057901 -0.320963  0.018431 -0.840684  0.355447  0.409505   \n",
      "6  -0.005224 -0.038841  0.033682  0.012251  0.016807 -0.022866 -0.018878   \n",
      "7   0.506974  0.007337  0.212477 -0.025603  0.011020 -0.422552 -0.401222   \n",
      "8   1.000000  0.028196  0.532519  0.008213  0.010848 -0.850068 -0.890568   \n",
      "9   0.028196  1.000000  0.036333 -0.015876  0.002990 -0.034187 -0.036981   \n",
      "10  0.532519  0.036333  1.000000  0.032807 -0.019341 -0.519452 -0.673756   \n",
      "11  0.008213 -0.015876  0.032807  1.000000 -0.028756  0.000793 -0.004675   \n",
      "12  0.010848  0.002990 -0.019341 -0.028756  1.000000 -0.007542 -0.005715   \n",
      "13 -0.850068 -0.034187 -0.519452  0.000793 -0.007542  1.000000  0.914402   \n",
      "14 -0.890568 -0.036981 -0.673756 -0.004675 -0.005715  0.914402  1.000000   \n",
      "15  0.841934  0.039062  0.725085  0.000660  0.005444 -0.847693 -0.975956   \n",
      "16  0.848989  0.038119  0.706853  0.001995  0.005747 -0.908216 -0.988394   \n",
      "17  0.762140  0.032933  0.735993 -0.000060  0.003729 -0.859966 -0.933724   \n",
      "18 -0.010803  0.005447  0.020993  0.030118 -0.960731  0.009246  0.005974   \n",
      "19 -0.700061 -0.025440 -0.787293 -0.010538  0.008019  0.802120  0.867237   \n",
      "\n",
      "          15        16        17        18        19  \n",
      "1  -0.811096 -0.905077 -0.867263  0.123172  0.804535  \n",
      "2  -0.664780 -0.652106 -0.604213  0.650301  0.557634  \n",
      "3   0.370847  0.414147  0.380186 -0.630842 -0.353200  \n",
      "4  -0.870573 -0.941772 -0.888705  0.009017  0.824460  \n",
      "5  -0.419355 -0.411024 -0.394640  0.789274  0.364130  \n",
      "6   0.021834  0.022447  0.024154 -0.012498 -0.028275  \n",
      "7   0.380596  0.379514  0.337786 -0.013186 -0.313775  \n",
      "8   0.841934  0.848989  0.762140 -0.010803 -0.700061  \n",
      "9   0.039062  0.038119  0.032933  0.005447 -0.025440  \n",
      "10  0.725085  0.706853  0.735993  0.020993 -0.787293  \n",
      "11  0.000660  0.001995 -0.000060  0.030118 -0.010538  \n",
      "12  0.005444  0.005747  0.003729 -0.960731  0.008019  \n",
      "13 -0.847693 -0.908216 -0.859966  0.009246  0.802120  \n",
      "14 -0.975956 -0.988394 -0.933724  0.005974  0.867237  \n",
      "15  1.000000  0.969500  0.918900 -0.004486 -0.854722  \n",
      "16  0.969500  1.000000  0.973466 -0.006447 -0.909907  \n",
      "17  0.918900  0.973466  1.000000 -0.004796 -0.945559  \n",
      "18 -0.004486 -0.006447 -0.004796  1.000000 -0.004746  \n",
      "19 -0.854722 -0.909907 -0.945559 -0.004746  1.000000  \n"
     ]
    }
   ],
   "source": [
    "#the first benchmark linear model\n",
    "#pearson correlation \n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X is your DataFrame of features\n",
    "correlation_matrix = train_X.corr(method='pearson')\n",
    "\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce4d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.110040020010005\n"
     ]
    }
   ],
   "source": [
    "#from the correlation table, we can easily some highly related parameters\n",
    "#I use Ridge to treat potential multicollinearity\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.RidgeCV(alphas=np.linspace(0.01, 100, 2000))\n",
    "reg.fit(x_subtrain_train_scaled, y_subtrain_train.values.ravel())\n",
    "\n",
    "print(\"Best alpha:\", reg.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faed5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefs: [[-0.19933268  0.06840095  0.88547204  0.49093417  0.16434762  0.00825083\n",
      "  -0.04078904 -0.05364764 -0.00482149  0.05728051 -0.00090782  0.17537197\n",
      "   0.02931285 -0.17585513  0.13288882  0.47480467 -0.07856005 -0.00215498\n",
      "   0.02873281]]\n",
      "intercept: [6.40328274e-18]\n"
     ]
    }
   ],
   "source": [
    "# we set up our ridge regression\n",
    "reg = linear_model.Ridge(alpha=.11)\n",
    "reg.fit(x_subtrain_train_scaled, y_subtrain_train_scaled)\n",
    "\n",
    "reg.coef_\n",
    "\n",
    "reg.intercept_\n",
    "print(\"coefs:\", reg.coef_\n",
    "      )\n",
    "print(\"intercept:\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09efb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE from Ridge: 1567.036376157547\n",
      "Validation_RMSE_Ridge: 39.58581028800026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_ridge = reg.predict(x_val_train_scaled)\n",
    "\n",
    "# Reshape predictions\n",
    "y_val_pred_scaled =y_val_pred_ridge.reshape(-1, 1)\n",
    "\n",
    "# Calculate MSE\n",
    "y_val_true_ridge = y_scalar.inverse_transform(y_val_train_scaled)\n",
    "y_val_pred_ridge = y_scalar.inverse_transform(y_val_pred_scaled)\n",
    "mse_val = mean_squared_error(y_val_true_ridge, y_val_pred_ridge)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "\n",
    "print(\"Validation MSE from Ridge:\", mse_val)\n",
    "print(\"Validation_RMSE_Ridge:\", rmse_val)\n",
    "Validation_RMSE_Ridge = rmse_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a370b",
   "metadata": {},
   "source": [
    "The second benchmark-- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e64e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b959d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False, 'max_depth': 165, 'max_features': 'sqrt', 'n_estimators': 182}\n"
     ]
    }
   ],
   "source": [
    "#tuning the hyper parameters in random forest\n",
    "param_dist = {\n",
    "    'n_estimators': randint(20, 200),\n",
    "    'max_depth': randint(10,200),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=200,  #how many protential combinations explored\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    random_state=20\n",
    ")\n",
    "#fit our training data \n",
    "random_search.fit(x_subtrain_train_scaled, y_subtrain_train_scaled.ravel())\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b53fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(bootstrap=False, max_depth=19, max_features=&#x27;sqrt&#x27;,\n",
       "                      n_estimators=179, random_state=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(bootstrap=False, max_depth=19, max_features=&#x27;sqrt&#x27;,\n",
       "                      n_estimators=179, random_state=20)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=19, max_features='sqrt',\n",
       "                      n_estimators=179, random_state=20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model the random forest based on the hyperparameters\n",
    "\n",
    "Random_forest= RandomForestRegressor(\n",
    "    bootstrap=False,\n",
    "    max_depth=19,\n",
    "    max_features='sqrt',\n",
    "    n_estimators=179,\n",
    "    random_state=20\n",
    ")\n",
    "\n",
    "Random_forest.fit(x_subtrain_train_scaled, y_subtrain_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4058da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE from random forest: 432.31\n",
      "Validation_RMSE_rf: 20.79\n"
     ]
    }
   ],
   "source": [
    "#evaluation on the random forest model\n",
    "\n",
    "y_val_pred_rf = Random_forest.predict(x_val_train_scaled).reshape(-1, 1)\n",
    "\n",
    "y_val_pred_rf = y_scalar.inverse_transform(y_val_pred_rf)\n",
    "y_val_true_rf = y_scalar.inverse_transform(y_val_train_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_val_true_rf, y_val_pred_rf )\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Validation MSE from random forest: {mse:.2f}\")\n",
    "print(f\"Validation_RMSE_rf: {rmse:.2f}\")\n",
    "Validation_RMSE_rf=rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f84a8",
   "metadata": {},
   "source": [
    "The third benchmark-- neural netwrok without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d7d2c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: early stopping\n"
     ]
    }
   ],
   "source": [
    "#define earlystopping\n",
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",     # Watch validation loss\n",
    "    min_delta=0,            # Consider any small improvement as valid\n",
    "    patience=5,             # Stop if no improvement for 5 consecutive epochs\n",
    "    verbose=1,              # Print stopping message\n",
    "    mode=\"min\"              # Stop when validation loss stops decreasing\n",
    ")\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(x_subtrain_train_scaled.shape[1],)))\n",
    "model.add(keras.layers.Dense(units=100,activation='relu',kernel_initializer='he_normal',\n",
    "                              kernel_regularizer=regularizers.l2(0.01))) \n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(units=150,activation='relu',kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(units=200,activation='relu',kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=regularizers.l2(0.01))) \n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(units=1,activation='linear')) \n",
    "model.compile(optimizer=keras.optimizers.Adam(),loss='mse')\n",
    "\n",
    "\n",
    "model_training_history=model.fit(\n",
    "    x=x_subtrain_train_scaled,\n",
    "    y=y_subtrain_train_scaled,\n",
    "    validation_data=(x_val_train_scaled,y_val_train_scaled),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es_callback],\n",
    "    verbose=0\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "848d9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Validation MSE from NN keras : 741.4163\n",
      "Validation_RMSE_NN_non: 27.2290\n"
     ]
    }
   ],
   "source": [
    "# valuation on the neural network\n",
    "y_pred_scaled_nnk = model.predict(x_val_train_scaled)\n",
    "#rescaled \n",
    "y_pred_rescaled_nnk = y_scalar.inverse_transform(y_pred_scaled_nnk)\n",
    "y_val_rescaled = y_scalar.inverse_transform(y_val_train_scaled)\n",
    "\n",
    "mse_original = mean_squared_error(y_val_rescaled, y_pred_rescaled_nnk)\n",
    "rmse_original = np.sqrt(mse_original)\n",
    "\n",
    "\n",
    "print(f\"Validation MSE from NN keras : {mse_original:.4f}\")\n",
    "print(f\"Validation_RMSE_NN_non: {rmse_original:.4f}\")\n",
    "Validation_RMSE_NN_non=rmse_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637e206",
   "metadata": {},
   "source": [
    "Building the Neural Network with Hyperparameter Tuning\n",
    "First, we tune the hyperparameters using Optuna.\n",
    "Then, we construct a neural network using the Functional API and incorporate early stopping to prevent overfitting.\n",
    "Next, we train the model using the optimized hyperparameters.\n",
    "Finally, we evaluate the model’s performance on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4370fa",
   "metadata": {},
   "source": [
    "Tuning hyperparameter using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93af32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_tf_model(nr_input_features: int,\n",
    "                   list_units: list,\n",
    "                   alpha: float,\n",
    "                   dropout_rate: float,\n",
    "                   activation: str) -> tf.keras.Model:\n",
    "\n",
    "    input_layer = tf.keras.layers.Input(shape=(nr_input_features,))\n",
    "    hidden_output = input_layer\n",
    "\n",
    "    for idx, units in enumerate(list_units):\n",
    "        hidden_output = tf.keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation=activation,\n",
    "            kernel_initializer='he_normal' if activation == 'relu' else 'glorot_normal',\n",
    "            kernel_regularizer=regularizers.l2(alpha)\n",
    "        )(hidden_output)\n",
    "        hidden_output = tf.keras.layers.Dropout(dropout_rate)(hidden_output)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(units=1, activation='linear')(hidden_output)\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_test_model(training: bool,\n",
    "                     model: tf.keras.Model,\n",
    "                     x_batch_data: tf.Tensor,\n",
    "                     y_batch_data: tf.Tensor,\n",
    "                     optimizer: tf.keras.optimizers.Optimizer = None) -> tf.Tensor:\n",
    "    if training:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions_train = model(x_batch_data, training=True)\n",
    "            current_batch_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.MSE(\n",
    "                y_pred=tf.squeeze(predictions_train, axis=-1),\n",
    "                y_true=tf.squeeze(y_batch_data, axis=-1)\n",
    "            ))\n",
    "        gradients = tape.gradient(current_batch_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    else:\n",
    "        predictions_test = model(x_batch_data, training=False)\n",
    "        current_batch_loss = tf.reduce_mean(tf.keras.losses.MSE(\n",
    "            y_pred=tf.squeeze(predictions_test, axis=-1),\n",
    "            y_true=tf.squeeze(y_batch_data, axis=-1)\n",
    "        ))\n",
    "    return current_batch_loss\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Sample architecture\n",
    "    max_hidden_layers = 5\n",
    "    hidden_units_list = []\n",
    "    keep_sampling_hidden_units = True\n",
    "    nr_hidden_layer = 0\n",
    "\n",
    "    while keep_sampling_hidden_units:\n",
    "        if nr_hidden_layer == 0:\n",
    "            current_hidden_units = trial.suggest_int(f\"Units_hidden_layer_{nr_hidden_layer}\", 10, 200, step=10)\n",
    "        else:\n",
    "            current_hidden_units = trial.suggest_int(f\"Units_hidden_layer_{nr_hidden_layer}\", 0, 200, step=10)\n",
    "\n",
    "        if current_hidden_units == 0 or nr_hidden_layer == max_hidden_layers - 1:\n",
    "            keep_sampling_hidden_units = False\n",
    "\n",
    "        if current_hidden_units != 0:\n",
    "            hidden_units_list.append(current_hidden_units)\n",
    "\n",
    "        nr_hidden_layer += 1\n",
    "\n",
    "    # Other hyperparameters\n",
    "    current_optimizer = trial.suggest_categorical(\"Optimizer\", ['adam', 'sgd','Adamw'])\n",
    "    current_learning_rate = trial.suggest_float(\"Learning_Rate\", 1e-4, 1e-3, log=True)\n",
    "    current_activation = trial.suggest_categorical(\"Activation\", ['tanh', 'relu','gelu'])\n",
    "    current_alpha = trial.suggest_float(\"alpha\", 1e-5, 1, log=True)\n",
    "    current_dropout = trial.suggest_float(\"dropout\", 0.1, 0.4, step=0.1)\n",
    "    current_batch_size = trial.suggest_categorical(\"batch_size\", [16,32, 64])\n",
    "    \n",
    "    # Build model\n",
    "    model = build_tf_model(\n",
    "        nr_input_features=x_subtrain_train.shape[1],\n",
    "        list_units=hidden_units_list,\n",
    "        dropout_rate=current_dropout,\n",
    "        activation=current_activation,\n",
    "        alpha=current_alpha\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.get({\n",
    "        'class_name': current_optimizer,\n",
    "        'config': {'learning_rate': current_learning_rate}\n",
    "    })\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    patience = 10\n",
    "    nr_epochs = 100\n",
    "\n",
    "    for epoch in range(nr_epochs):\n",
    "        for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_subtrain_train_scaled, y_subtrain_train_scaled)).batch(current_batch_size):\n",
    "            train_test_model(True, model, x_batch, y_batch, optimizer)\n",
    "\n",
    "        val_losses = []\n",
    "        for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_val_train_scaled, y_val_train_scaled)).batch(current_batch_size):\n",
    "            val_loss = train_test_model(False, model, x_batch, y_batch)\n",
    "            val_losses.append(val_loss.numpy())\n",
    "\n",
    "        mean_val_loss = np.mean(val_losses)\n",
    "\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            best_val_loss = mean_val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "            break\n",
    "\n",
    "    print(\"[DEBUG] MSE returned to Optuna:\", best_val_loss)\n",
    "    return float(best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(),direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "if study.best_trial is not None:\n",
    "    best_params = study.best_trial.params\n",
    "    print(\"Number of finished trials:\", len(study.trials))\n",
    "    print(\"Number of successful trials:\", len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "else:\n",
    "    print(\"No successful trials.\")\n",
    "    print(f\"Training stopped at epoch {epoch}, best epoch: {best_epoch}, best val loss: {best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a2500",
   "metadata": {},
   "source": [
    "Final Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6fbec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped at epoch 21, best epoch: 16, best val loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'Units_hidden_layer_0': 170,\n",
    "    'Units_hidden_layer_1': 180,\n",
    "    'Units_hidden_layer_2': 130,\n",
    "    'Units_hidden_layer_3': 120,\n",
    "    'Units_hidden_layer_4': 90,\n",
    "    #'Units_hidden_layer_5': 160,\n",
    "    #'Units_hidden_layer_6': 200,\n",
    "    #'Units_hidden_layer_7': 200,\n",
    "    #'Units_hidden_layer_8': 180,\n",
    "    #'Units_hidden_layer_9': 80,\n",
    "    'Optimizer': 'Adamw',\n",
    "    'Learning_Rate':0.0005256588893435302,\n",
    "    'Activation': 'gelu',\n",
    "    'alpha':  0.09546607173825271,\n",
    "    'dropout': 0.1,\n",
    "    'batch_size': 32\n",
    "}\n",
    "# 1. Extract the list_units from best_params\n",
    "list_units = [\n",
    "    best_params['Units_hidden_layer_0'],\n",
    "    best_params['Units_hidden_layer_1'],\n",
    "    best_params['Units_hidden_layer_2'],\n",
    "    best_params['Units_hidden_layer_3'],\n",
    "    best_params['Units_hidden_layer_4'],\n",
    "    #best_params['Units_hidden_layer_5'],\n",
    "    #best_params['Units_hidden_layer_6'],\n",
    "    #best_params['Units_hidden_layer_7'],\n",
    "    #best_params['Units_hidden_layer_8'],\n",
    "    #best_params['Units_hidden_layer_9']\n",
    "]\n",
    "\n",
    "# 2. Create the model with best hyperparameters\n",
    "tf_model = build_tf_model(\n",
    "    nr_input_features=train_X.shape[1],\n",
    "    list_units=list_units,\n",
    "    dropout_rate=best_params['dropout'],\n",
    "    activation=best_params['Activation'],\n",
    "    alpha=best_params['alpha']\n",
    ")\n",
    "\n",
    "# 3. Set optimizer with best learning rate\n",
    "tf_optimizer = tf.keras.optimizers.get({\n",
    "    'class_name': best_params['Optimizer'],\n",
    "    'config': {'learning_rate': best_params['Learning_Rate']}\n",
    "})\n",
    "\n",
    "# 4. Optional – set batch size\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_subtrain_train_scaled, y_subtrain_train_scaled)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val_train_scaled, y_val_train_scaled)).batch(batch_size)\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = [] \n",
    "best_val_loss = float('inf')\n",
    "wait = 0\n",
    "patience = 5\n",
    "nr_epochs = 100\n",
    "best_epoch = 0\n",
    "final_epoch = nr_epochs\n",
    "\n",
    "for epoch in range(nr_epochs):\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "    for x_batch_train, y_batch_train in train_dataset:\n",
    "        train_loss = train_test_model(True, tf_model, x_batch_train, y_batch_train, tf_optimizer)\n",
    "        epoch_train_loss.append(train_loss.numpy())\n",
    "    \n",
    "    epoch_mean_loss = np.mean(epoch_train_loss)\n",
    "    train_loss_list.append(epoch_mean_loss)\n",
    "\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_loss = train_test_model(False, tf_model, x_batch_val, y_batch_val)\n",
    "        epoch_val_loss.append(val_loss.numpy())\n",
    "\n",
    "    mean_val_loss = np.mean(epoch_val_loss)\n",
    "    val_loss_list.append(mean_val_loss)\n",
    "\n",
    "    \n",
    "    if mean_val_loss < best_val_loss:\n",
    "        best_val_loss = mean_val_loss\n",
    "        best_epoch = epoch\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    if wait >= patience:\n",
    "        final_epoch=epoch\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training stopped at epoch {final_epoch}, best epoch: {best_epoch}, best val loss: {best_val_loss:.4f}\")\n",
    "# Visualize the model performance:\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(train_loss_list,label='Train Loss')\n",
    "plt.plot(val_loss_list,label='Val Loss')\n",
    "plt.ylabel('MSE Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Train vs. Validation Performance')#\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ab619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE_NN-T 222.45135906511973 Test_RMSE_NN_T: 14.914803353216554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Convert validation set to full tensor\n",
    "x_val_train_tensor = tf.convert_to_tensor(x_val_train_scaled, dtype=tf.float32)\n",
    "\n",
    "# Predict using trained model\n",
    "y_pred_scaled = tf_model(x_val_train_tensor).numpy()\n",
    "\n",
    "y_pred_rescaled = y_scalar.inverse_transform(y_pred_scaled)\n",
    "y_true_rescaled = y_scalar.inverse_transform(y_val_train_scaled)\n",
    "mse_original = mean_squared_error(y_true_rescaled, y_pred_rescaled)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_true_rescaled, y_pred_rescaled))\n",
    "print(\"Test MSE_NN-T\",mse_original,\n",
    "    \"Test_RMSE_NN_T:\", test_rmse)\n",
    "Test_RMSE_NN_T=test_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48498f0",
   "metadata": {},
   "source": [
    "Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41cc800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ac223_row0_col1 {\n",
       "  background-color: #004529;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ac223_row1_col1 {\n",
       "  background-color: #ddf1a6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ac223_row2_col1 {\n",
       "  background-color: #b2df90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ac223_row3_col1 {\n",
       "  background-color: #ffffe5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ac223\">\n",
       "  <caption>Validation RMSE Comparison Table</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ac223_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ac223_level0_col1\" class=\"col_heading level0 col1\" >Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ac223_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ac223_row0_col0\" class=\"data row0 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_ac223_row0_col1\" class=\"data row0 col1\" >39.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac223_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ac223_row1_col0\" class=\"data row1 col0\" >Random Forest</td>\n",
       "      <td id=\"T_ac223_row1_col1\" class=\"data row1 col1\" >20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac223_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ac223_row2_col0\" class=\"data row2 col0\" >Neural Network (Baseline)</td>\n",
       "      <td id=\"T_ac223_row2_col1\" class=\"data row2 col1\" >23.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac223_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ac223_row3_col0\" class=\"data row3 col0\" >Neural Network (Tuned)</td>\n",
       "      <td id=\"T_ac223_row3_col1\" class=\"data row3 col1\" >14.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x31a72ed50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat RMSE comparision table\n",
    "rmse_table = pd.DataFrame({\n",
    "    'Model': ['Ridge Regression', 'Random Forest', 'Neural Network (Baseline)', 'Neural Network (Tuned)'],\n",
    "    'Validation RMSE': [Validation_RMSE_Ridge,Validation_RMSE_rf ,Validation_RMSE_NN_non,Test_RMSE_NN_T]})\n",
    "\n",
    "#print(rmse_table)\n",
    "rmse_table.style.set_caption(\"Validation RMSE Comparison Table\") \\\n",
    "    .format({\"Validation RMSE\": \"{:.2f}\"}) \\\n",
    "    .background_gradient(subset=[\"Validation RMSE\"], cmap=\"YlGn\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33802ccd",
   "metadata": {},
   "source": [
    "Prediction on Test Set and Export of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a30137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the test_y\n",
    "y_pred_scaled = tf_model.predict(x_test_scaled)\n",
    "#  Inverse transform to original scale\n",
    "y_pred_rescaled = y_scalar.inverse_transform(y_pred_scaled)\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    'predicted_y': y_pred_rescaled.flatten()  # flatten() to make it a 1D array\n",
    "})\n",
    "# output predictions\n",
    "prediction_df.to_csv('predictions_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4153c5",
   "metadata": {},
   "source": [
    "Why is this architeture suitable for my task?\n",
    "The five layers with gradually decreasing neurons(170-180-130-120-90) can captures complex patterns in the data. Gelu Guassian error linear unit can smooth the transformation, and AdamW optimizer improve the model generalization.The appropriate dropout rate and L2 regularization prevent overfitting, balancing the model complexity and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760249c0",
   "metadata": {},
   "source": [
    " Based on the plot you should interpret the model fit with max. 2 sentences. \n",
    "Both the validation loss and training loss decrease smoothly and converge to a low MSE. The lower validation loss indicates that the model achieves good regularization without signs of overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
